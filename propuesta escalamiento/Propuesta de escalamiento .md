# üöÄPropuesta para el escalamiento de la aplicaci√≥n en n8n + aws + python

Para escalar la soluci√≥n y soportar un alto volumen de trabajo, es necesario migrar desde la arquitectura monol√≠tica predeterminada de n8n hacia un modelo basado en colas (queue mode), el cual habilita el escalamiento horizontal tanto del motor de flujos (n8n) como del microservicio en Python.

## üèóÔ∏è Arquitectura con colas y workers

El primer paso para lograr esta modularizaci√≥n es modificar el archivo docker-compose, agregando las variables de entorno necesarias para activar el queue mode de n8n. Esto permite separar los componentes en:

-	n8n Main: instancia responsable de la interfaz visual, el disparo de workflows y la comunicaci√≥n con Redis.
-	n8n Workers: procesos independientes dedicados exclusivamente al procesamiento de tareas en paralelo.

Con estas consideraciones, la arquitectura queda de la siguiente manera:

1. **n8n Main**
-	Eje-cuta la interfaz visual.
-	Inicia los workflows.
	Realiza la primera fase del flujo: extracci√≥n y validaci√≥n del documento.
-	Env√≠a las tareas a Redis para su procesamiento as√≠ncrono.
2. **Extracci√≥n previa (primer paso del flujo)**
La extracci√≥n del archivo se ejecuta antes de encolar la tarea.
Esto es cr√≠tico por varias razones:
-	Los documentos PDF ya llegan convertidos a JSON, por lo que la extracci√≥n es ligera.
-	Ahorrar peso en la cola (Redis) mejora el rendimiento del sistema, ya que Redis opera en memoria.
-	Se detectan errores temprano: si el JSON no es v√°lido, el flujo se detiene sin ocupar workers ni saturar la cola.
-	Los workers procesan √∫nicamente las partes m√°s pesadas: API externa, l√≥gica del servicio Python, comparaci√≥n, etc.
Al encolar solo JSON limpio y validado, el sistema se vuelve m√°s estable, r√°pido y escalable.

3. **Redis como motor de colas** 

Redis se utiliza como sistema de mensajes entre n8n Main y los n8n Workers.
Redis almacena:
-	tareas livianas listas para procesar
-	trabajos pendientes cuando los workers est√°n ocupados
-	estado de ejecuci√≥n de cada workflow
Redis no almacena PDF, ni binarios, sino √∫nicamente los datos ya extra√≠dos.
Esto garantiza un throughput alto, bajo consumo de memoria y m√≠nima latencia.

4. **n8n Workers**
Son instancias dedicadas exclusivamente al procesamiento en paralelo:
-	consumen mensajes desde Redis
-	hacen llamadas a APIs externas (p. ej., Apoc API)
-	realizan la l√≥gica de decisi√≥n
-	se comunican con el microservicio Python
Cada worker consume CPU y memoria, por lo que es necesario ajustar su n√∫mero mediante pruebas de carga.
________________________________________
5. **Escalamiento del microservicio en Python**
El microservicio que procesa los Pok√©mon tambi√©n puede escalar para evitar convertirse en un cuello de botella, por lo tanto se propone:

-	AWS Lambda: escalamiento inmediato a miles de invocaciones, pago por uso.

________________________________________
6. **Integraci√≥n con un servicio de colas de AWS (opcional)**
Si se requiere una arquitectura a√∫n m√°s desacoplada, se puede incorporar AWS SQS entre n8n y Python.
Ventajas:
-	Persistencia garantizada (no depende de RAM)
-	Desacople total entre n8n y Python
-	Ideal para cargas masivas o sistemas distribuidos
En ese caso Redis se usa para los workers de n8n, y SQS para las tareas que van hacia Python.
Diagrama de arquitectura

7. **Diagrama de arquitectura**

 El diagrama de la soluci√≥n es el siguiente:

[Diagrama de arquitectura](https://www.mermaidchart.com/d/a9611c24-418a-4b94-8348-1929a219e259)

## üìà Escalamiento vertical y pruebas de carga
Aunque el escalado horizontal aumenta la capacidad de procesamiento, este depende de los recursos f√≠sicos disponibles en el servidor o entorno de despliegue. Cada worker de n8n consume CPU y memoria, por lo que se recomienda realizar pruebas de carga para determinar cu√°ntos workers puede soportar la infraestructura sin degradaci√≥n.
Tambi√©n debe considerarse el escalamiento vertical:
-	M√°s CPU = mayor capacidad para procesar flujos pesados (PDF, APIs, l√≥gica).
-	M√°s RAM = mayor estabilidad con workers concurrentes.
En entornos productivos es com√∫n combinar escalado vertical + horizontal para obtener el mejor rendimiento posible.

## üîÅ Orquestador con retry autom√°tico

Para el seguimiento de las colas, adem√°s de lo mencionado anteriormente, es posible agregar una arquitectura para generar un orquestador que permita generar un re try automatico para controlar el alto flujo de entradas.

Esta arquetectura seria otro flujo independiente con colas creadas por redis. Se expone como un elemento separado porque a pesar de ser importante el flujo puede realizarse sin el orquestador y el re try se puede realizar con SQS. Sin embargo esta opci√≥n a pesar de agregar mayor complejidad permite un control total.

[Fuente para las opciones de escalamiento](https://www.youtube.com/watch?v=mJw4MJRGt24&t=1096s)

[Diagrama del orquestador](https://www.mermaidchart.com/d/afe178f7-fb31-4cb3-b430-7af3ffcf54ea)

## üè∑Ô∏èVersionamiento y despliegue
Para mantener un control estructurado de versiones se propone utilizar un esquema est√°ndar de etiquetado:
usuario-docker/nombre-servicio:1.0.0
Donde:
-	1 = versi√≥n mayor
-	0 = cambios importantes compatibles
-	0 = correcciones menores

Las im√°genes deben subirse a un registro remoto, como Docker Hub o Amazon ECR, especialmente si la infraestructura opera en la nube.
El archivo docker-compose.yml debe mantenerse bajo control de versiones en GitHub. Adem√°s, se recomienda incluir un pipeline de CI/CD (con GitHub Actions, por ejemplo) que ejecute:
1.	Generaci√≥n de la imagen Docker.
2.	Publicaci√≥n en el registro remoto.
3.	Despliegue autom√°tico en la infraestructura (VPS, EC2, ECS, etc.).

Esto asegura reproducibilidad, trazabilidad y despliegues consistentes.

## üìú Centralizaci√≥n de logs

Para mantener un registro claro y unificado del comportamiento del sistema, se propone centralizar los logs en un √∫nico servicio de observabilidad. Dado que la soluci√≥n se apoya en AWS, la opci√≥n m√°s adecuada es CloudWatch Logs, el cual se integra f√°cilmente con aplicaciones basadas en Docker.
Para ello puede instalarse y configurarse el AWS CloudWatch Agent en el servidor (o usar el driver de logs de Docker si todo se ejecuta en contenedores). Este agente recopila los logs generados por:
-	n8n Main
-	n8n Workers
-	Servicio Python
-	Redis (opcional)

y los env√≠a a CloudWatch, donde pueden visualizarse, filtrarse y analizarse. Esto es esencial en arquitecturas distribuidas, ya que facilita identificar cuellos de botella, errores y picos de carga.

Es importate mencionar que esta opci√≥n no solo permite recolectar logs sino insight importantes como:

- Tiempos de ejecui√≥n
-	Numero de workers en trabajo
- N√∫mero de entradas exitosas 
- N√∫mero de entradas fallidas 


## üîê IAM y seguridad
Se recomienda seguir el principio de Least Privilege:
-	Cada servicio debe tener solo los permisos estrictamente necesarios.
-	n8n solo debe leer/escribir en su cola (Redis o SQS).
-	Python solo debe poder consumir su propia cola y hacer sus llamadas externas.
-	Roles separados para despliegue, ejecuci√≥n y logging.

Esto es una recomendaci√≥n oficial de AWS y evita configuraciones peligrosas en producci√≥n.


